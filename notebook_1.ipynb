{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69564f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''yes, you can absolutely use library to automatically extract vocabulary from text data. below are the most commonly used library and how to use them to get the vocabulary, depending on your use case:'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233ffffe",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51bd1e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0167b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b5a8f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes, you can absolutely use library to automatically extract vocabulary from text data. below are the most commonly used library and how to use them to get the vocabulary, depending on your use case:\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenizer.encode(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01c2851",
   "metadata": {},
   "source": [
    "# Labeling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7eed99",
   "metadata": {},
   "source": [
    "### if the first token is input then the second token will be the output, if 1st and 2nd token is input the 3rd token will be the out put."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6026bc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''yes, you can absolutely use library to automatically extract vocabulary from text data. below are the most commonly used library and how to use them to get the vocabulary, depending on your use case:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a585900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "209e42d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = tokenizer.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be2075a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8505] --------> 11\n",
      "[8505, 11] --------> 345\n",
      "[8505, 11, 345] --------> 460\n",
      "[8505, 11, 345, 460] --------> 5543\n",
      "[8505, 11, 345, 460, 5543] --------> 779\n",
      "[8505, 11, 345, 460, 5543, 779] --------> 5888\n",
      "[8505, 11, 345, 460, 5543, 779, 5888] --------> 284\n",
      "[8505, 11, 345, 460, 5543, 779, 5888, 284] --------> 6338\n",
      "[8505, 11, 345, 460, 5543, 779, 5888, 284, 6338] --------> 7925\n"
     ]
    }
   ],
   "source": [
    "#context size, here we are using 1024 as context size\n",
    "\n",
    "context_size = 1024\n",
    "\n",
    "for i in range(1,len(encoded_text[:10])):\n",
    "    print(encoded_text[:i],\"-------->\" ,encoded_text[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b7bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49d80b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class MiniLLMTokenizer:\n",
    "    def __init__(self, txt, tokenizer, context_size, stride):\n",
    "        self.input_ids = []\n",
    "        self.target_ids = []\n",
    "    \n",
    "        token_ids = tokenizer.encode(text)\n",
    "        \n",
    "        for i in range(1, len(token_ids)- context_size, stride):\n",
    "            input_chunk = token_ids[i:i + context_size]\n",
    "            target_chunk = token_ids[i + 1: i + context_size + 1]\n",
    "            self.input_ids.append(torch.tensor(input_chunk))\n",
    "            self.target_ids.append(torch.tensor(target_chunk))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.target_ids[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51baa11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(text, batch_size =8, context_size=256, stride=128, shuffle = True, drop_last = True, n_workers=0):\n",
    "\n",
    "    tokenizer = tiktoken.get_encoding('gpt2')\n",
    "\n",
    "    dataset = MiniLLMTokenizer(text, tokenizer,context_size,stride=stride)\n",
    "    dataloader = DataLoader(\n",
    "            dataset=dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            drop_last=drop_last,\n",
    "            num_workers=n_workers\n",
    "    )\n",
    "\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b369e78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[2420, 1366,   13, 2174]]), tensor([[1366,   13, 2174,  389]])]\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(data_loader(text, batch_size=1,context_size=4, stride=1)))) #used small context size and stride because of small dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b5f59",
   "metadata": {},
   "source": [
    "# Token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3bd75899",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.tensor([2, 3, 1, 4], dtype=torch.long)\n",
    "vocab_size = 6\n",
    "output_size = 3\n",
    "torch.manual_seed(123)\n",
    "embedding_layer = torch.nn.Embedding(vocab_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6dbf0b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [-1.1589,  0.3255, -0.6315]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "41222dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.1690],\n",
      "        [ 0.9178,  1.5810,  1.3010],\n",
      "        [ 1.2753, -0.2010, -0.1606],\n",
      "        [-0.4015,  0.9666, -1.1481],\n",
      "        [-1.1589,  0.3255, -0.6315],\n",
      "        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(embedding_layer.weight) #weight size is limited because it small vocb ise but for implementation we wil use large context size\n",
    "\n",
    "#These are intial weights, these will be optimized during training and adjust according training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b07f05",
   "metadata": {},
   "source": [
    "# Adding Positional Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d38bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
